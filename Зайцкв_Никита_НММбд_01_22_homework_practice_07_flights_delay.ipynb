{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrGBvlq7OvbI"
      },
      "source": [
        "# Домашнее задание 7 - предсказание задержки авиарейсов\n",
        "\n",
        "\n",
        "### О задании\n",
        "\n",
        "Практическое задание посвящено изучению основных библиотек для анализа данных, а также линейных моделей и методов их обучения. Вы научитесь:\n",
        " * применять библиотеки NumPy и Pandas для осуществления желаемых преобразований;\n",
        " * подготавливать данные для обучения линейных моделей;\n",
        " * обучать линейную, Lasso и Ridge-регрессии при помощи модуля scikit-learn;\n",
        " * реализовывать обычный и стохастический градиентные спуски;\n",
        " * обучать линейную регрессию для произвольного функционала качества.\n",
        "\n",
        "\n",
        "### Оценивание и штрафы\n",
        "\n",
        "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце Вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке.\n",
        "\n",
        "\n",
        "### Формат сдачи\n",
        "Для сдачи задания получившийся файл \\*.ipynb с решением необходимо выложить в свой репозиторий github."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoTd6Tc4OvbL"
      },
      "source": [
        "### Pandas\n",
        "\n",
        "![](https://metrouk2.files.wordpress.com/2015/10/panda.jpg)\n",
        "\n",
        "#### Ответьте на вопросы о данных по авиарейсам в США за январь-апрель 2008 года.\n",
        "\n",
        "Данные находятся в приложенном файле `2008.csv`. Их [описание](http://stat-computing.org/dataexpo/2009/the-data.html) приведено ниже:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQRLjXUUOvbM"
      },
      "source": [
        "Airline on-time performance\n",
        "\n",
        "Have you ever been stuck in an airport because your flight was delayed or cancelled and wondered if you could have predicted it if you'd had more data? This is your chance to find out.\n",
        "\n",
        "The data\n",
        "The data set is available for download here.\n",
        "The data consists of flight arrival and departure details for all commercial flights within the USA, from October 1987 to April 2008. This is a large dataset: there are nearly 120 million records in total, and takes up 1.6 gigabytes of space compressed and 12 gigabytes when uncompressed.\n",
        "\n",
        "Understanding and preparing the data\n",
        "In order to answer above questions, we are going to analyze the provided dataset, containing up to 1936758 ### different internal flights in the US for 2008 and their causes for delay, diversion and cancellation\n",
        "\n",
        "The data comes from the U.S. Department of Transportation’s (DOT) Bureau of Transportation Statistics (BTS). Meta data explanations\n",
        "\n",
        "This dataset is composed by the following variables:\n",
        "\n",
        "**Year** 2008 **Month** 1-12 **DayofMonth** 1-31 **DayOfWeek** 1 (Monday) - 7 (Sunday)  \n",
        "**DepTime** actual departure time (local, hhmm)  \n",
        "**CRSDepTime** scheduled departure time (local, hhmm)  \n",
        "**ArrTime** actual arrival time (local, hhmm)  \n",
        "**CRSArrTime** scheduled arrival time (local, hhmm)  \n",
        "**UniqueCarrier** unique carrier code  \n",
        "**FlightNum** flight number  \n",
        "**TailNum** plane tail number: aircraft registration, unique aircraft identifier  \n",
        "**ActualElapsedTime** in minutes  \n",
        "**CRSElapsedTime** in minutes  \n",
        "**AirTime** in minutes  \n",
        "**ArrDelay** arrival delay, in minutes: A flight is counted as “on time” if it operated less than 15 minutes later the scheduled time shown in the carriers’ Computerized Reservations Systems (CRS).  \n",
        "**DepDelay** departure delay, in minutes  \n",
        "**Origin** origin IATA airport code  \n",
        "**Dest** destination IATA airport code  \n",
        "**Distance** in miles  \n",
        "**TaxiIn** taxi in time, in minutes  \n",
        "**TaxiOut** taxi out time in minutes  \n",
        "**Cancelled** *was the flight cancelled  \n",
        "**CancellationCode** reason for cancellation (A = carrier, B = weather, C = NAS, D = security)  \n",
        "**Diverted** 1 = yes, 0 = no  \n",
        "**CarrierDelay** in minutes: Carrier delay is within the control of the air carrier. Examples of occurrences that may determine carrier delay are: aircraft cleaning, aircraft damage, awaiting the arrival of connecting passengers or crew, baggage, bird strike, cargo loading, catering, computer, outage-carrier equipment, crew legality (pilot or attendant rest), damage by hazardous goods, engineering inspection, fueling, handling disabled passengers, late crew, lavatory servicing, maintenance, oversales, potable water servicing, removal of unruly passenger, slow boarding or seating, stowing carry-on baggage, weight and balance delays.  \n",
        "**WeatherDelay** in minutes: Weather delay is caused by extreme or hazardous weather conditions that are forecasted or manifest themselves on point of departure, enroute, or on point of arrival.  \n",
        "**NASDelay** in minutes: Delay that is within the control of the National Airspace System (NAS) may include: non-extreme weather conditions, airport operations, heavy traffic volume, air traffic control, etc.  \n",
        "**SecurityDelay** in minutes: Security delay is caused by evacuation of a terminal or concourse, re-boarding of aircraft because of security breach, inoperative screening equipment and/or long lines in excess of 29 minutes at screening areas.  \n",
        "**LateAircraftDelay** in minutes: Arrival delay at an airport due to the late arrival of the same aircraft at a previous airport. The ripple effect of an earlier delay at downstream airports is referred to as delay propagation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "joW7yAKsOvbM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2OdnkKgOvbO"
      },
      "source": [
        "**1.** Какая из причин отмены рейса (`CancellationCode`) была самой частой? (расшифровки кодов можно найти в описании данных)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Haj6g9wOvbO",
        "outputId": "c28fb154-cfb9-4970-cace-c6dd16a267ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наиболее частой причиной отмены рейса является ' A ' 563 -вхождениями.\n"
          ]
        }
      ],
      "source": [
        "plane = pd.read_csv('2008.csv')\n",
        "cancellation_counts = plane['CancellationCode'].value_counts()\n",
        "most_common_reason = cancellation_counts.index[0]\n",
        "\n",
        "print('Наиболее частой причиной отмены рейса является', \"'\", most_common_reason,\"'\", cancellation_counts[0], '-вхождениями.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала импортируем необходимую библиотеку NumPy. Затем загружаем датасет из CSV-файла в датафрейм Pandas.\n",
        "Теперь посчитаем количество появлений каждого кода отмены рейса с помощью метода value_counts(). Далее находим наиболее частые причины отмены рейса.\n",
        "Теперь мы можем сделать вывод наиболее частой причины отмены рейса и количества её вхождений."
      ],
      "metadata": {
        "id": "M-1bIhqOSJFe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsevlRqmOvbP"
      },
      "source": [
        "**2.** Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_1NNDLDOvbP",
        "outputId": "d58e9a33-0aa8-4054-9e4e-4d04be221e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Среднее расстояние, пройденное самолетом: 724.51\n",
            "Минимальное расстояние, пройденное самолетом: 31\n",
            "Максимальное расстояние, пройденное самолетом: 4962\n"
          ]
        }
      ],
      "source": [
        "\n",
        "plane = pd.read_csv('2008.csv')\n",
        "\n",
        "plane = plane.dropna(subset=['Distance'])\n",
        "\n",
        "mean_distance = np.mean(plane['Distance'])\n",
        "min_distance = np.min(plane['Distance'])\n",
        "max_distance = np.max(plane['Distance'])\n",
        "\n",
        "# Вывод статистических показателей расстояния\n",
        "print(f'Среднее расстояние, пройденное самолетом: {mean_distance:.2f}')\n",
        "print(f'Минимальное расстояние, пройденное самолетом: {min_distance}')\n",
        "print(f'Максимальное расстояние, пройденное самолетом: {max_distance}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Последовательность действий в программе:\n",
        "1. Загружаем датасет из CSV-файла в датафрейм Pandas.\n",
        "2. Очистка данных от пропусков с помощью метода dropna().\n",
        "3. Подсчет статистических показателей расстояния с помощью функций np.mean(), np.min(), и np.max().\n",
        "4. Вывод статистических показателей расстояния."
      ],
      "metadata": {
        "id": "7scNdE5-SsMY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K35OtOHVOvbP"
      },
      "source": [
        "**3.** Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Фильтрация данных для получения информации о рейсах с минимальным расстоянием\n",
        "min_distance_flights = plane[plane['Distance'] == min_distance]\n",
        "\n",
        "# Вывод информации о днях и рейсах с минимальным пройденным расстоянием\n",
        "print('Дни и рейсы с минимальным пройденным расстоянием:')\n",
        "print(min_distance_flights[['Year', 'Month', 'DayofMonth', 'FlightNum']])\n",
        "\n",
        "# Фильтрация данных для получения информации о рейсах с тем же номером\n",
        "same_flightnum_flights = plane[plane['FlightNum'].apply(lambda x: x in min_distance_flights['FlightNum'].values)]\n",
        "\n",
        "# Вывод информации о расстоянии, пройденном этими рейсами в другие дни\n",
        "print('\\nРасстояние, пройденное этими же рейсами в другие дни:')\n",
        "print(same_flightnum_flights[['Year', 'Month', 'DayofMonth', 'Distance']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PBwRbG1c8ys",
        "outputId": "df355580-13cc-4146-eb7e-000f4527c1fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дни и рейсы с минимальным пройденным расстоянием:\n",
            "       Year  Month  DayofMonth  FlightNum\n",
            "1116   2008     12          30         65\n",
            "6958   2008     12          26         65\n",
            "17349  2008      8          18         64\n",
            "27534  2008      3          11         64\n",
            "46082  2008      8           9         65\n",
            "48112  2008      2          28         64\n",
            "\n",
            "Расстояние, пройденное этими же рейсами в другие дни:\n",
            "       Year  Month  DayofMonth  Distance\n",
            "501    2008      3          20       533\n",
            "1116   2008     12          30        31\n",
            "1389   2008      3          13       680\n",
            "1517   2008      7          10       680\n",
            "2619   2008      5          23      2381\n",
            "...     ...    ...         ...       ...\n",
            "66529  2008     12          21        82\n",
            "67172  2008      3          22       533\n",
            "68264  2008      9           7       386\n",
            "68338  2008      8           3      2454\n",
            "69305  2008      1           5      1005\n",
            "\n",
            "[78 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtkgLHhSOvbQ"
      },
      "source": [
        "**4.** Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKWOIzBEOvbQ",
        "outputId": "cf3bd24b-4c8e-4250-bf07-adc13294d183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Аэропорт с наибольшим количеством вылетов - ATL с количеством вылетов 4134.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Подсчет количества вылетов из каждого аэропорта\n",
        "counts_by_airport = plane['Origin'].value_counts()\n",
        "\n",
        "# Нахождение аэропорта с наибольшим количеством вылетов\n",
        "most_frequent_airport = counts_by_airport.index[0]  # Наиболее часто встречающийся аэропорт\n",
        "number_of_flights = counts_by_airport[0]  # Количество вылетов из этого аэропорта\n",
        "\n",
        "# Вывод информации о самом популярном аэропорте\n",
        "print(f'Аэропорт с наибольшим количеством вылетов - {most_frequent_airport} с количеством вылетов {number_of_flights}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Последовательность действий:\n",
        "1. Загрузка данных из CSV-файла в датафрейм Pandas.\n",
        "2. Подсчет количества вылетов из каждого аэропорта с помощью метода value_counts().\n",
        "3. Нахождение аэропорта с наибольшим количеством вылетов путем извлечения первого индекса с наибольшим количеством вылетов.\n",
        "4. Получение количества вылетов из этого аэропорта.\n",
        "5. Вывод информации о самом популярном аэропорте с наибольшим количеством вылетов."
      ],
      "metadata": {
        "id": "SZNR75-edcm9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA_1A1HYOvbQ"
      },
      "source": [
        "**5.** Найдите для каждого аэропорта среднее время полета (`AirTime`) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQPG4RrAOvbR",
        "outputId": "8040c578-1a1a-4865-93db-4c1ce7f21cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Аэропорт с наибольшим средним временем полета - SJU со значением 205.2.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Группировка данных по аэропортам и вычисление среднего времени полета (AirTime)\n",
        "average_airtime_by_airport = plane.groupby('Origin')['AirTime'].mean()\n",
        "\n",
        "# Нахождение аэропорта с наибольшим средним временем полета\n",
        "airport_with_max_airtime = average_airtime_by_airport.idxmax()\n",
        "max_airtime_value = average_airtime_by_airport.max()\n",
        "\n",
        "# Вывод информации об аэропорте с наибольшим средним временем полета\n",
        "print(f'Аэропорт с наибольшим средним временем полета - {airport_with_max_airtime} со значением {max_airtime_value}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Комментарии к программе:\n",
        "1. Загрузка данных из CSV-файла в датафрейм Pandas.\n",
        "2. Группировка данных по аэропортам (Origin) с помощью метода groupby() и вычисление среднего времени полета (AirTime) с помощью метода mean().\n",
        "3. Нахождение аэропорта с наибольшим средним временем полета с помощью метода idxmax(), который возвращает индекс максимального значения.\n",
        "4. Вывод информации об аэропорте с наибольшим средним временем полета."
      ],
      "metadata": {
        "id": "TmNLVJgGfIOU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NDKMnQAOvbR"
      },
      "source": [
        "**6.** Найдите аэропорт, у которого наибольшая доля задержанных (`DepDelay > 0`) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию `filter` после `groupby`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qDCcuGRtOvbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a733fae-40f0-4945-e736-95ece68b3edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Аэропорт с наибольшей долей задержанных рейсов: EWR\n",
            "Доля задержанных рейсов в этом аэропорте: 0.5111591072714183\n"
          ]
        }
      ],
      "source": [
        "# Группировка данных по аэропортам вылета\n",
        "grouped_airports = plane.groupby('Origin')\n",
        "\n",
        "# Фильтрация аэропортов с количеством рейсов больше 1000\n",
        "filtered_airports = grouped_airports.filter(lambda x: len(x) > 1000)\n",
        "\n",
        "# Рассчитываем долю задержанных рейсов для каждого аэропорта\n",
        "delayed_flights_percentage = filtered_airports.groupby('Origin')['DepDelay'].apply(lambda x: (x > 0).mean())\n",
        "\n",
        "# Находим аэропорт с наибольшей долей задержанных рейсов\n",
        "airport_with_highest_delay_percentage = delayed_flights_percentage.idxmax()\n",
        "highest_delay_percentage = delayed_flights_percentage.max()\n",
        "\n",
        "print(\"Аэропорт с наибольшей долей задержанных рейсов:\", airport_with_highest_delay_percentage)\n",
        "print(\"Доля задержанных рейсов в этом аэропорте:\", highest_delay_percentage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dilyts_tOvbR"
      },
      "source": [
        "## Линейная регрессия\n",
        "\n",
        "В этой части мы разберемся с линейной регрессией, способами её обучения и измерением качества ее прогнозов.\n",
        "\n",
        "Будем рассматривать датасет из предыдущей части задания для предсказания времени задержки отправления рейса в минутах (DepDelay). Отметим, что под задержкой подразумевается не только опоздание рейса относительно планируемого времени вылета, но и отправление до планируемого времени.\n",
        "\n",
        "### Подготовка данных\n",
        "\n",
        "**7.** Считайте выборку из файла при помощи функции pd.read_csv и ответьте на следующие вопросы:\n",
        "   - Имеются ли в данных пропущенные значения?\n",
        "   - Сколько всего пропущенных элементов в таблице \"объект-признак\"?\n",
        "   - Сколько объектов имеют хотя бы один пропуск?\n",
        "   - Сколько признаков имеют хотя бы одно пропущенное значение?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pyxaAIhOvbS",
        "outputId": "9160d6e0-aa9b-4eb2-fb28-6be9c63f039b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Имеются ли в данных пропущенные значения: True\n",
            "Общее количество пропущенных элементов в таблице \"объект-признак\": 355215\n",
            "Количество объектов с хотя бы одним пропуском: 70000\n",
            "Количество признаков с хотя бы одним пропущенным значением: 16\n"
          ]
        }
      ],
      "source": [
        "plane = pd.read_csv('2008.csv')\n",
        "\n",
        "# Проверка наличия пропущенных значений в данных\n",
        "missing_values = plane.isnull().values.any()\n",
        "\n",
        "# Подсчет общего количества пропущенных элементов в таблице \"объект-признак\"\n",
        "total_missing = plane.isnull().sum().sum()\n",
        "\n",
        "# Подсчет объектов с хотя бы одним пропуском\n",
        "objects_with_missing = plane.isnull().any(axis=1).sum()\n",
        "\n",
        "# Подсчет признаков с хотя бы одним пропущенным значением\n",
        "features_with_missing = plane.isnull().any(axis=0).sum()\n",
        "\n",
        "# Вывод результатов\n",
        "print(f'Имеются ли в данных пропущенные значения: {missing_values}')\n",
        "print(f'Общее количество пропущенных элементов в таблице \"объект-признак\": {total_missing}')\n",
        "print(f'Количество объектов с хотя бы одним пропуском: {objects_with_missing}')\n",
        "print(f'Количество признаков с хотя бы одним пропущенным значением: {features_with_missing}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Порядок действий:\n",
        "1. Загрузка данных из файла в датафрейм Pandas.\n",
        "2. Проверка наличия пропущенных значений в данных с помощью метода isnull() и оператора any().\n",
        "3. Подсчет общего количества пропущенных элементов в таблице \"объект-признак\" с помощью метода isnull() и оператора sum().\n",
        "Подсчет объектов с хотя бы одним пропуском с помощью метода isnull(), оператора any() и оператора sum().\n",
        "4. Подсчет признаков с хотя бы одним пропущенным значением с помощью метода isnull(), оператора any() и оператора sum().\n",
        "5. Вывод результатов в консоль с помощью оператора print()."
      ],
      "metadata": {
        "id": "j0kPyyHnhEbd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gglKZM3OvbS"
      },
      "source": [
        "Как вы понимаете, также не имеет смысла рассматривать при решении поставленной задачи объекты с пропущенным значением целевой переменной. В связи с этим ответьте на следующие вопросы и выполните соответствующие действия:\n",
        "- Имеются ли пропущенные значения в целевой переменной?\n",
        "- Проанализируйте объекты с пропущенными значениями целевой переменной. Чем вызвано это явление? Что их объединяет? Можно ли в связи с этим, на ваш взгляд, исключить какие-то признаки из рассмотрения? Обоснуйте свою точку зрения.\n",
        "\n",
        "Исключите из выборки объекты **с пропущенным значением целевой переменной и со значением целевой переменной, равным 0**, а также при необходимости исключите признаки в соответствии с вашим ответом на последний вопрос из списка и выделите целевую переменную в отдельный вектор, исключив её из матрицы \"объект-признак\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "3QVmo_E2OvbS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jISl0ZfQOvbT"
      },
      "source": [
        "**8.** Обратите внимание, что признаки DepTime, CRSDepTime, ArrTime, CRSArrTime приведены в формате hhmm, в связи с чем будет не вполне корректно рассматривать их как вещественные.\n",
        "\n",
        "Преобразуйте каждый признак FeatureName из указанных в пару новых признаков FeatureName\\_Hour, FeatureName\\_Minute, разделив каждое из значений на часы и минуты. Не забудьте при этом исключить исходный признак из выборки. В случае, если значение признака отсутствует, значения двух новых признаков, его заменяющих, также должны отсутствовать.\n",
        "\n",
        "Например, признак DepTime необходимо заменить на пару признаков DepTime_Hour, DepTime_Minute. При этом, например, значение 155 исходного признака будет преобразовано в значения 1 и 55 признаков DepTime_Hour, DepTime_Minute соответственно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA_yDZF5OvbT",
        "outputId": "c1880e5e-1e6e-4950-ffab-648bc86951cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Year  Month  DayofMonth  DayOfWeek UniqueCarrier  FlightNum TailNum  \\\n",
            "0  2008      6          18          3            WN        242  N699SW   \n",
            "1  2008      6           4          3            XE       2380  N15980   \n",
            "2  2008      8           3          7            WN       1769  N464WN   \n",
            "3  2008      1          23          3            OO       3802  N465SW   \n",
            "4  2008      5           4          7            WN        399  N489WN   \n",
            "\n",
            "   ActualElapsedTime  CRSElapsedTime  AirTime  ...  SecurityDelay  \\\n",
            "0               57.0            65.0     46.0  ...            NaN   \n",
            "1              124.0           138.0    108.0  ...            NaN   \n",
            "2              138.0           155.0    125.0  ...            NaN   \n",
            "3              102.0           111.0     79.0  ...            NaN   \n",
            "4              148.0           160.0    136.0  ...            NaN   \n",
            "\n",
            "   LateAircraftDelay DepTime_Hour DepTime_Minute  CRSDepTime_Hour  \\\n",
            "0                NaN         21.0           11.0               20   \n",
            "1                NaN         14.0           26.0               14   \n",
            "2                NaN         11.0           43.0               11   \n",
            "3                NaN         11.0           41.0               11   \n",
            "4                NaN          8.0           15.0                8   \n",
            "\n",
            "   CRSDepTime_Minute  ArrTime_Hour  ArrTime_Minute CRSArrTime_Hour  \\\n",
            "0                 55          23.0             8.0              23   \n",
            "1                 10          17.0            30.0              17   \n",
            "2                 45          15.0             1.0              15   \n",
            "3                 44          13.0            23.0              13   \n",
            "4                 20          12.0            43.0              13   \n",
            "\n",
            "   CRSArrTime_Minute  \n",
            "0                  0  \n",
            "1                 28  \n",
            "2                 20  \n",
            "3                 35  \n",
            "4                  0  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ],
      "source": [
        "plane = pd.read_csv('2008.csv')\n",
        "\n",
        "# Преобразование признаков в пару новых признаков\n",
        "for feature in ['DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime']:\n",
        "    plane[feature + '_Hour'] = plane[feature].apply(lambda x: x // 100 if x else np.nan)\n",
        "    plane[feature + '_Minute'] = plane[feature].apply(lambda x: x % 100 if x else np.nan)\n",
        "\n",
        "# Исключение исходных признаков из выборки\n",
        "plane = plane.drop(['DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime'], axis=1)\n",
        "\n",
        "# Вывод результатов\n",
        "print(plane.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPM5hAHPOvbT"
      },
      "source": [
        "**9.** Некоторые из признаков, отличных от целевой переменной, могут оказывать чересчур значимое влияние на прогноз, поскольку по своему смыслу содержат большую долю информации о значении целевой переменной. Изучите описание датасета и исключите признаки, сильно коррелирующие с ответами. Ваш выбор признаков для исключения из выборки обоснуйте. Кроме того, исключите признаки TailNum и Year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "I6hfFhjqOvbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd94b8c5-ff60-4cd6-fa40-6f76cd36940a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  CRSArrTime  \\\n",
            "0      6          18          3   2111.0        2055   2308.0        2300   \n",
            "1      6           4          3   1426.0        1410   1730.0        1728   \n",
            "2      8           3          7   1143.0        1145   1501.0        1520   \n",
            "3      1          23          3   1141.0        1144   1323.0        1335   \n",
            "4      5           4          7    815.0         820   1243.0        1300   \n",
            "\n",
            "   FlightNum  ActualElapsedTime  CRSElapsedTime  AirTime  Distance  TaxiIn  \\\n",
            "0        242               57.0            65.0     46.0       307     3.0   \n",
            "1       2380              124.0           138.0    108.0       834     4.0   \n",
            "2       1769              138.0           155.0    125.0       997     4.0   \n",
            "3       3802              102.0           111.0     79.0       532     4.0   \n",
            "4        399              148.0           160.0    136.0      1090     4.0   \n",
            "\n",
            "   TaxiOut  Cancelled  Diverted  WeatherDelay  NASDelay  SecurityDelay  \n",
            "0      8.0          0         0           NaN       NaN            NaN  \n",
            "1     12.0          0         0           NaN       NaN            NaN  \n",
            "2      9.0          0         0           NaN       NaN            NaN  \n",
            "3     19.0          0         0           NaN       NaN            NaN  \n",
            "4      8.0          0         0           NaN       NaN            NaN  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Загрузка данных\n",
        "plane = pd.read_csv('2008.csv')\n",
        "\n",
        "# Исключение признаков TailNum и Year\n",
        "plane = plane.drop(['TailNum', 'Year'], axis=1)\n",
        "\n",
        "# Исключение категориальных признаков\n",
        "plane = plane.select_dtypes(exclude=['object'])\n",
        "\n",
        "# Вычисление матрицы корреляций между признаками и целевой переменной\n",
        "correlations = plane.corr()['ArrDelay'].abs().sort_values(ascending=False)\n",
        "\n",
        "# Отбор признаков с высокой корреляцией (больше 0.5) с целевой переменной\n",
        "highly_correlated_features = correlations[correlations > 0.5].index.tolist()\n",
        "\n",
        "# Исключение выбранных признаков из датасета\n",
        "plane = plane.drop(highly_correlated_features, axis=1)\n",
        "\n",
        "print(plane.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Последовательность действий:\n",
        "1. Загрузка данных из файла '2008.csv' в переменную data.\n",
        "2. Исключение признаков 'TailNum' и 'Year' из датасета, так как они не будут использоваться в анализе.\n",
        "3. Исключение категориальных признаков (признаков типа 'object') из датасета, чтобы избежать ошибок при вычислении корреляций.\n",
        "4. Вычисление матрицы корреляций между числовыми признаками и целевой переменной 'ArrDelay', затем сортировка по абсолютным значениям корреляции в порядке убывания.\n",
        "5. Отбор признаков с высокой корреляцией (больше 0.5) с целевой переменной 'ArrDelay'.\n",
        "6. Исключение выбранных признаков с высокой корреляцией из датасета.\n",
        "7. Вывод первых строк обновленного датасета на экран."
      ],
      "metadata": {
        "id": "1fh9Yu184eDr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaaTypy8OvbU"
      },
      "source": [
        "**10.** Приведем данные к виду, пригодному для обучения линейных моделей. Для этого вещественные признаки надо отмасштабировать, а категориальные — привести к числовому виду. Также надо устранить пропуски в данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPvKntrHOvbU"
      },
      "source": [
        "В первую очередь поймем, зачем необходимо применять масштабирование. Следующие ячейки с кодом построят гистограммы для 3 вещественных признаков выборки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "scrolled": true,
        "id": "pARpl4C5OvbU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "2bb5dd6f-9c53-4d1b-9bd8-5cc0eb9d399c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-4e7f6b755b72>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DepTime_Hour'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ],
      "source": [
        "X['DepTime_Hour'].hist(bins=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3cIgWcuOvbU"
      },
      "outputs": [],
      "source": [
        "X['TaxiIn'].hist(bins=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb0BOb_FOvbU"
      },
      "outputs": [],
      "source": [
        "X['FlightNum'].hist(bins=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPj9rVK_OvbV"
      },
      "source": [
        "Какую проблему вы наблюдаете на этих графиках? Как масштабирование поможет её исправить?"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "28zvXyziOvbV"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig8h_DreOvbV"
      },
      "source": [
        "Некоторые из признаков в нашем датасете являются категориальными. Типичным подходом к работе с ними является бинарное, или [one-hot-кодирование](https://en.wikipedia.org/wiki/One-hot).\n",
        "\n",
        "Реализуйте функцию transform_data, которая принимает на вход DataFrame с признаками и выполняет следующие шаги:\n",
        "1. Замена пропущенных значений на нули для вещественных признаков и на строки 'nan' для категориальных.\n",
        "2. Масштабирование вещественных признаков с помощью [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
        "3. One-hot-кодирование категориальных признаков с помощью [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) или функции [pd.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html).\n",
        "\n",
        "Метод должен возвращать преобразованный DataFrame, который должна состоять из масштабированных вещественных признаков и закодированных категориальных (исходные признаки должны быть исключены из выборки)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "a5wkq2AxOvbV"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "def transform_data(plane):\n",
        "    # Замена пропущенных значений на нули для вещественных признаков и на 'nan' для категориальных\n",
        "    data_numeric = plane.select_dtypes(include=['float64', 'int64']).fillna(0)\n",
        "    data_categorical = plane.select_dtypes(include=['object']).fillna('nan')\n",
        "\n",
        "    # Масштабирование вещественных признаков\n",
        "    scaler = StandardScaler()\n",
        "    data_scaled = scaler.fit_transform(data_numeric)\n",
        "\n",
        "    # One-hot-кодирование категориальных признаков\n",
        "    encoder = DictVectorizer(sparse=False)\n",
        "    data_encoded = encoder.fit_transform(data_categorical.T.to_dict().values())\n",
        "\n",
        "    # Создание нового DataFrame с масштабированными вещественными и закодированными категориальными признаками\n",
        "    transformed_data = pd.DataFrame(data_scaled, columns=data_numeric.columns)\n",
        "    transformed_data = pd.concat([transformed_data, pd.DataFrame(data_encoded, columns=encoder.get_feature_names_out())], axis=1)\n",
        "\n",
        "    return transformed_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Эта функция:\n",
        "1. Заменяет пропущенные значения на нули для вещественных признаков и на 'nan' для категориальных.\n",
        "2. Масштабирует вещественные признаки с помощью StandardScaler.\n",
        "3. Кодирует категориальные признаки с помощью DictVectorizer.\n",
        "4. Возвращает преобразованный DataFrame с масштабированными вещественными и закодированными категориальными признаками."
      ],
      "metadata": {
        "id": "oYI_tTk-58ZD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8GAAyb4OvbV"
      },
      "source": [
        "Примените функцию transform_data к данным. Сколько признаков получилось после преобразования?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "6m5ztSPxOvbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7106f331-e623-4b9f-c6a3-10dc404aee7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество признаков после преобразования: 5765\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Загрузка данных из файла\n",
        "plane = pd.read_csv(\"2008.csv\")\n",
        "\n",
        "# Применение функции transform_data\n",
        "transformed_data = transform_data(plane)\n",
        "\n",
        "print(\"Количество признаков после преобразования:\", transformed_data.shape[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Комментарии к коду:\n",
        "1. Загрузка данных из файла\n",
        "2. Используем функцию read_csv из библиотеки pandas для загрузки данных из файла \"2008.csv\" и сохраняем их в переменную data\n",
        "3. Применение функции transform_data\n",
        "4. Выводим количество признаков (столбцов) в преобразованных данных, используя атрибут shape, где [1] обозначает количество столбцов"
      ],
      "metadata": {
        "id": "jFfH3VVf-F8Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7-XofRAOvbW"
      },
      "source": [
        "**11.** Разбейте выборку и вектор целевой переменной на обучение и контроль в отношении 70/30 (для этого можно использовать, например, функцию [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "q2YSFOVoOvbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e669d9-395c-41f5-bff1-01bf54b7d33d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер обучающего набора данных: (49000, 5764) (49000,)\n",
            "Размер тестового набора данных: (21000, 5764) (21000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Разделение данных на признаки (X) и целевую переменную (y)\n",
        "X = transformed_data.drop('ArrDelay', axis=1)  # замените 'target_column' на название вашего столбца с целевой переменной\n",
        "y = transformed_data['ArrDelay']\n",
        "\n",
        "# Разделение на обучающий и тестовый наборы данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Вывод размеров обучающих и тестовых наборов данных\n",
        "print(\"Размер обучающего набора данных:\", X_train.shape, y_train.shape)\n",
        "print(\"Размер тестового набора данных:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-mX84-OOvbW"
      },
      "source": [
        "### Scikit-learn\n",
        "\n",
        "<img src = \"https://pp.vk.me/c4534/u35727827/93547647/x_d31c4463.jpg\">\n",
        "Теперь, когда мы привели данные к пригодному виду, попробуем решить задачу при помощи метода наименьших квадратов. Напомним, что данный метод заключается в оптимизации функционала $MSE$:\n",
        "\n",
        "$$MSE(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 \\to \\min_{w},$$\n",
        "\n",
        "где $\\{ (x_i, y_i ) \\}_{i=1}^l$ — обучающая выборка, состоящая из $l$ пар объект-ответ.\n",
        "\n",
        "Заметим, что решение данной задачи уже реализовано в модуле sklearn в виде класса [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression).\n",
        "\n",
        "**12.** Обучите линейную регрессию на 1000 объектах из обучающей выборки и выведите значения $MSE$ и $R^2$ на этой подвыборке и контрольной выборке (итого 4 различных числа). Проинтерпретируйте полученный результат — насколько качественные прогнозы строит полученная модель? Какие проблемы наблюдаются в модели?\n",
        "\n",
        "**Подсказка**: изучите значения полученных коэффициентов $w$, сохраненных в атрибуте coef_ объекта LinearRegression."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.isnull().sum())\n"
      ],
      "metadata": {
        "id": "aKRumpg1oZO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Разделение данных на признаки (X) и целевую переменную (y)\n",
        "X = plane.drop('ArrDelay', axis=1)  # замените 'target_column' на название вашего столбца с целевой переменной\n",
        "y = plane['ArrDelay']\n",
        "\n",
        "# Разделение на обучающий и тестовый наборы данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Вывод размеров обучающих и тестовых наборов данных\n",
        "print(\"Размер обучающего набора данных:\", X_train.shape, y_train.shape)\n",
        "print(\"Размер тестового набора данных:\", X_test.shape, y_test.shape)\n",
        "\n",
        "X = X.dropna(subset=['ArrDelay'])\n",
        "y = y.dropna()\n"
      ],
      "metadata": {
        "id": "5f-BYXziocJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plane = pd.read_csv(\"2008.csv\")\n",
        "plane.head()"
      ],
      "metadata": {
        "id": "XY9TxSkYuJE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "baY2fnx4OvbW"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Объединение обучающего и тестового наборов данных\n",
        "X_combined = pd.concat([X_train, X_test])\n",
        "\n",
        "# Создание экземпляра OneHotEncoder и преобразование всех уникальных значений категориального признака\n",
        "encoder = OneHotEncoder()\n",
        "X_combined_encoded = encoder.fit_transform(X_combined).toarray()\n",
        "\n",
        "# Разделение обратно на обучающий и тестовый наборы данных\n",
        "X_train_encoded = X_combined_encoded[:len(X_train)]\n",
        "X_test_encoded = X_combined_encoded[len(X_train):]\n",
        "\n",
        "# Обучение модели на преобразованных данных\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Предсказание и вычисление метрик\n",
        "y_train_pred = model.predict(X_train_encoded)\n",
        "y_test_pred = model.predict(X_test_encoded)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"MSE на обучающей выборке:\", mse_train)\n",
        "print(\"R^2 на обучающей выборке:\", r2_train)\n",
        "print(\"MSE на контрольной выборке:\", mse_test)\n",
        "print(\"R^2 на контрольной выборке:\", r2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "KvUc-uVDOvbk"
      },
      "source": [
        "Для решения описанных вами в предыдущем пункте проблем используем L1- или L2-регуляризацию, тем самым получив Lasso и Ridge регрессии соответственно и изменив оптимизационную задачу одним из следующих образов:\n",
        "$$MSE_{L1}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_1 \\to \\min_{w},$$\n",
        "$$MSE_{L2}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_2^2 \\to \\min_{w},$$\n",
        "\n",
        "где $\\alpha$ — коэффициент регуляризации. Один из способов его подбора заключается в переборе некоторого количества значений и оценке качества на кросс-валидации для каждого из них, после чего выбирается значение, для которого было получено наилучшее качество."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkGmmUflOvbk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w02R52eoOvbk"
      },
      "source": [
        "**13.** Обучение линейной регрессии.\n",
        "\n",
        "\n",
        "\n",
        "Обучите линейную регрессию с $L_1$ (Lasso) и $L_2$ (Ridge) регуляризаторами (используйте параметры по умолчанию). Посмотрите, какое количество коэффициентов близко к 0 (степень близости к 0 определите сами из разумных пределов). Постройте график зависимости числа ненулевых коэффициентов от коэффицента регуляризации (перебирайте значения по логарифмической сетке от $10^{-3}$ до $10^3$). Согласуются ли результаты с вашими ожиданиями?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4_87SUkKOvbl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Преобразование категориальных признаков\n",
        "encoder = OneHotEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "\n",
        "# Создание списка значений коэффициента регуляризации\n",
        "a = np.logspace(-3, 3, 100)\n",
        "\n",
        "# Инициализация списков для хранения количества ненулевых коэффициентов\n",
        "non_zero_coeffs_lasso = []\n",
        "non_zero_coeffs_ridge = []\n",
        "\n",
        "# Обучение моделей с различными значениями alpha\n",
        "for alpha in a:\n",
        "    lasso = Lasso(alpha=alpha)\n",
        "    lasso.fit(X_train, y_train)\n",
        "    non_zero_coeffs_lasso.append(np.sum(lasso.coef_ != 0))\n",
        "\n",
        "    ridge = Ridge(alpha=alpha)\n",
        "    ridge.fit(X_train, y_train)\n",
        "    non_zero_coeffs_ridge.append(np.sum(ridge.coef_ != 0))\n",
        "\n",
        "# Построение графика\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(a, non_zero_coeffs_lasso, label='Lasso')\n",
        "plt.plot(a, non_zero_coeffs_ridge, label='Ridge')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('Number of non-zero coefficients')\n",
        "plt.title('Number of non-zero coefficients vs Alpha')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT1H_zTbOvbl"
      },
      "source": [
        "Посчитайте для Ridge-регрессии следующие метрики: $RMSE$, $MAE$, $R^2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "atac87SdOvbm"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfW-DMYbOvbm"
      },
      "source": [
        "Подберите на обучающей выборке для Ridge-регрессии коэффициент регуляризации (перебирайте значения по логарифмической сетке от $10^{-3}$ до $10^3$) для каждой из метрик при помощи кросс-валидации c 5 фолдами на тех же 1000 объектах. Для этого воспользуйтесь GridSearchCV и KFold из sklearn. Постройте графики зависимости фукнции потерь от коэффициента регуляризации. Посчитайте те же метрики снова. Заметно ли изменилось качество?\n",
        "\n",
        "Для выполнения данного задания вам могут понадобиться реализованные в библиотеке объекты [LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html), [RidgeCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) и [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aF-Q9yLGOvbm"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Ehnh05UCOvbn"
      },
      "source": [
        "**14.** Поиск объектов-выбросов\n",
        "\n",
        "\n",
        "Как известно, MSE сильно штрафует за большие ошибки на объектах-выбросах. С помощью cross_val_predict сделайте Out-of-Fold предсказания для обучающей выборки. Посчитайте ошибки и посмотрите на их распределение (plt.hist). Что вы видите?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU9C9rPvOvbn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Загрузка данных\n",
        "data = pd.read_csv('2008.csv')\n",
        "\n",
        "# Предобработка данных (например, удаление пропущенных значений)\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Определение признаков и целевой переменной\n",
        "X = data.drop('ArrDelay', axis=1)\n",
        "y = data['ArrDelay']\n",
        "\n",
        "# Создание модели линейной регрессии\n",
        "model = LinearRegression()\n",
        "\n",
        "# Получение Out-of-Fold предсказаний\n",
        "predictions = cross_val_predict(model, X, y, cv=5)\n",
        "\n",
        "# Вычисление ошибок\n",
        "errors = y - predictions\n",
        "\n",
        "# Построение гистограммы распределения ошибок\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(errors, bins=50, color='skyblue', edgecolor='black')\n",
        "plt.xlabel('Errors')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Errors')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}